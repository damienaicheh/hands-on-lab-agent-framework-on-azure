---
published: true
type: workshop
title: "Parte 3: Listo para ProducciÃ³n"
short_title: "ProducciÃ³n"
description: OrquestaciÃ³n avanzada, observabilidad y evaluaciÃ³n
level: advanced
authors:
  - Olivier Mertens
contacts:
  - "@olivMertens"
duration_minutes: 65
tags: orquestaciÃ³n, handoff, opentelemetry, evaluaciÃ³n, producciÃ³n
banner_url: ../../../assets/banner.jpg
navigation_levels: 1
sections_title:
  - IntroducciÃ³n
  - CÃ³digo de las Partes 1-2
  - MÃ³dulo 6 - OrquestaciÃ³n
  - MÃ³dulo 7 - Observabilidad
  - MÃ³dulo 8 - EvaluaciÃ³n
  - Resumen
---

# Parte 3: Listo para ProducciÃ³n

![Banner del Taller](../../../assets/banner.jpg)

> ğŸŒ **[â† Parte 2: Conocimiento](./part2-knowledge.es.md)** | **[Parte 4 â†’](./part4-advanced.es.md)**

## ğŸ“¦ CÃ³digo de las Partes 1 y 2

<details>
<summary>ğŸ“ Estructura del Proyecto (clic para expandir)</summary>

```text
helpdesk-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ module1_simple_agent.py      # Agente bÃ¡sico con streaming
â”‚   â”œâ”€â”€ module2_structured.py        # Salida estructurada Pydantic
â”‚   â”œâ”€â”€ module3_tools.py             # Herramientas de funciÃ³n
â”‚   â”œâ”€â”€ module4_ai_search.py         # IntegraciÃ³n RAG
â”‚   â””â”€â”€ module5_group_chat.py        # Multi-agente con MCP
â”œâ”€â”€ .env
â””â”€â”€ requirements.txt
```

</details>

<details>
<summary>ğŸ”§ Componentes Clave (clic para expandir)</summary>

```python
# Herramienta RAG de bÃºsqueda (mÃ³dulo 4)
@function_tool
async def search_knowledge_base(query: str) -> str:
    """Busca en la base de conocimiento."""
    search_client = SearchClient(
        endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
        index_name=os.getenv("AZURE_SEARCH_INDEX"),
        credential=AzureKeyCredential(os.getenv("AZURE_SEARCH_KEY"))
    )
    results = search_client.search(query, top=3)
    return "\n".join([doc["content"] for doc in results])

# ConfiguraciÃ³n cliente MCP (mÃ³dulo 5)
async with MCPServerStdio(
    params=StdioServerParameters(
        command="npx",
        args=["-y", "@modelcontextprotocol/server-filesystem", "./data"]
    )
) as mcp_server:
    tools = await mcp_server.list_tools()
```

</details>

<details>
<summary>ğŸ” Variables de Entorno (clic para expandir)</summary>

```bash
# .env - Valores requeridos de las partes anteriores
AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com/
AZURE_OPENAI_KEY=xxx
AZURE_OPENAI_DEPLOYMENT=gpt-4o

# AÃ±adido en la Parte 2
AZURE_SEARCH_ENDPOINT=https://xxx.search.windows.net
AZURE_SEARCH_KEY=xxx
AZURE_SEARCH_INDEX=helpdesk-index

# AÃ±adir para la Parte 3
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=xxx
```

</details>

<div class="info" data-title="Â¿No completaste las partes anteriores?">

> Completa [Parte 1](./part1-basics.es.md) y [Parte 2](./part2-knowledge.es.md) primero para tener todos los componentes.

</div>

---

Esta parte cubre funcionalidades para producciÃ³n:

| SecciÃ³n | Contenido |
|---------|-----------|
| **MÃ³dulo 6** | OrquestaciÃ³n Handoff |
| **MÃ³dulo 7** | Observabilidad OpenTelemetry |
| **MÃ³dulo 8** | EvaluaciÃ³n y Pruebas |

---

## MÃ³dulo 6 â€” OrquestaciÃ³n Handoff

Implementa transferencias inteligentes entre agentes especializados.

### ğŸ“š Concepto: PatrÃ³n Handoff

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO HANDOFF                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Usuario: "Tengo un problema con la VPN y necesito         â”‚
â”‚            crear un ticket"                                 â”‚
â”‚                    â”‚                                        â”‚
â”‚                    â–¼                                        â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚           â”‚ ğŸ¯ Orquestador â”‚                                â”‚
â”‚           â”‚   (Triaje)     â”‚                                â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                   â”‚ Analiza â†’ "Problema tÃ©cnico + ticket"  â”‚
â”‚                   â”‚                                        â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚      â–¼                         â–¼                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚ â”‚ ğŸ”§ TÃ©cnico  â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚ ğŸ“ Tickets  â”‚                   â”‚
â”‚ â”‚  Specialist â”‚ handoff â”‚  Specialist â”‚                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Componente | Rol |
|------------|-----|
| **Orquestador** | Triaje inicial, decide workflow |
| **Especialista TÃ©cnico** | Resuelve problemas tÃ©cnicos |
| **Especialista Tickets** | Crea y gestiona tickets |
| **Handoff** | Transferencia controlada |

### ğŸ§  PseudocÃ³digo

```
ALGORITMO: Workflow Handoff

1. CREAR AGENTES ESPECIALISTAS:
   - tech_specialist â†’ problemas tÃ©cnicos
   - ticket_specialist â†’ gestiÃ³n tickets

2. CREAR ORQUESTADOR con HandoffBuilder:
   - AÃ±adir especialistas disponibles
   - Definir instrucciones de triaje

3. HANDOFF CONDICIONAL:
   - Orquestador analiza solicitud
   - Decide especialista apropiado
   - Transfiere con contexto

4. FINALIZACIÃ“N:
   - Especialista completa tarea
   - Retorna al orquestador si necesario
```

### ğŸ”¨ Ejercicio

Crea `src/module6_orchestration.py`.

<details>
<summary>ğŸ’¡ Hint: Crear Especialistas</summary>

```python
tech_specialist = client.create_agent(
    name="TechSpecialist",
    instructions="""Eres un experto tÃ©cnico de TI.
    Resuelves problemas de hardware, software, red y seguridad.
    Proporciona pasos claros de soluciÃ³n.""",
    tools=[search_knowledge_base, run_diagnostics],
)

ticket_specialist = client.create_agent(
    name="TicketSpecialist",
    instructions="""Eres un experto en gestiÃ³n de tickets.
    Creas, actualizas y das seguimiento a tickets de soporte.""",
    tools=[create_ticket, update_ticket, get_ticket_status],
)
```

</details>

<details>
<summary>ğŸ’¡ Hint: Configurar Handoff</summary>

```python
from agent_framework.workflows import HandoffBuilder

orchestrator = (
    HandoffBuilder()
    .with_orchestrator(
        name="Orchestrator",
        instructions="""Eres el orquestador del helpdesk.
        Analiza cada solicitud y decide el especialista apropiado:
        - Problemas tÃ©cnicos â†’ TechSpecialist
        - Crear/gestionar tickets â†’ TicketSpecialist
        """
    )
    .add_specialist(tech_specialist)
    .add_specialist(ticket_specialist)
    .build()
)
```

</details>

### âœ… SoluciÃ³n

<details>
<summary>ğŸ“„ CÃ³digo Completo MÃ³dulo 6</summary>

```python
"""MÃ³dulo 6: OrquestaciÃ³n Avanzada - Workflow Handoff."""
import asyncio
import os
from azure.identity import DefaultAzureCredential
from agent_framework import ai_function
from agent_framework.azure_openai import AzureOpenAIChatClient
from agent_framework.workflows import HandoffBuilder


# Herramientas para especialistas
@ai_function
def search_knowledge_base(query: str) -> list[dict]:
    """Busca soluciones en la base de conocimiento."""
    return [
        {"title": "SoluciÃ³n VPN", "content": "Reinicia el cliente VPN..."},
        {"title": "Resetear conexiÃ³n", "content": "Flush DNS con ipconfig /flushdns..."},
    ]


@ai_function
def run_diagnostics(system: str) -> dict:
    """Ejecuta diagnÃ³sticos remotos."""
    return {
        "system": system,
        "status": "healthy",
        "checks": {"network": "ok", "disk": "ok", "memory": "ok"},
    }


@ai_function
def create_ticket(title: str, priority: str, description: str) -> dict:
    """Crea un nuevo ticket de soporte."""
    return {
        "ticket_id": "TK-2024-001",
        "title": title,
        "priority": priority,
        "status": "open",
    }


async def main() -> None:
    """Demuestra orquestaciÃ³n con Handoff."""
    
    client = AzureOpenAIChatClient(
        credential=DefaultAzureCredential(),
        endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        deployment_name="gpt-4o",
    )
    
    # Crear especialistas
    tech_specialist = client.create_agent(
        name="TechSpecialist",
        instructions="""Eres un experto tÃ©cnico de TI.
        Diagnosticas y resuelves problemas tÃ©cnicos.
        Usa las herramientas para buscar soluciones y ejecutar diagnÃ³sticos.""",
        tools=[search_knowledge_base, run_diagnostics],
    )
    
    ticket_specialist = client.create_agent(
        name="TicketSpecialist",
        instructions="""Eres un experto en gestiÃ³n de tickets.
        Creas tickets con la informaciÃ³n proporcionada.
        AsegÃºrate de incluir todos los detalles relevantes.""",
        tools=[create_ticket],
    )
    
    # Construir orquestador con Handoff
    orchestrator = (
        HandoffBuilder()
        .with_orchestrator(
            client=client,
            name="HelpdeskOrchestrator",
            instructions="""Eres el orquestador del helpdesk.
            
            ANALIZA cada solicitud y TRANSFIERE al especialista apropiado:
            - Problemas tÃ©cnicos (VPN, red, software) â†’ TechSpecialist
            - Crear o gestionar tickets â†’ TicketSpecialist
            
            Puedes transferir a mÃºltiples especialistas secuencialmente.
            Cuando todos los especialistas hayan terminado, resume el resultado.
            """,
        )
        .add_specialist(tech_specialist, "Problemas tÃ©cnicos de TI")
        .add_specialist(ticket_specialist, "GestiÃ³n de tickets de soporte")
        .with_max_handoffs(3)
        .build()
    )
    
    # Escenarios de prueba
    escenarios = [
        "Mi VPN no conecta desde esta maÃ±ana, necesito ayuda urgente",
        "Crea un ticket para reportar que la impresora del piso 3 no funciona",
        "Tengo problemas de red y necesito que quede registrado en un ticket",
    ]
    
    for escenario in escenarios:
        print(f"\n{'='*60}")
        print(f"ğŸ‘¤ Usuario: {escenario}")
        print("-" * 60)
        
        async for event in orchestrator.run_stream(escenario):
            if hasattr(event, 'handoff_to'):
                print(f"\nğŸ”„ Handoff a: {event.handoff_to}")
            if hasattr(event, 'text'):
                print(event.text, end="", flush=True)
        
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
```

</details>

```bash
python src/module6_orchestration.py
```

---

## MÃ³dulo 7 â€” Observabilidad OpenTelemetry

Implementa trazabilidad completa con OpenTelemetry y Azure Monitor.

### ğŸ“š Concepto: Â¿Por quÃ© Observabilidad?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  STACK DE OBSERVABILIDAD                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  TRACES (Trazas)                                           â”‚
â”‚  â”œâ”€â”€ request_span                                          â”‚
â”‚  â”‚   â”œâ”€â”€ orchestrator_span (200ms)                         â”‚
â”‚  â”‚   â”‚   â””â”€â”€ llm_call_span (150ms)                         â”‚
â”‚  â”‚   â”œâ”€â”€ tool_call_span (50ms)                             â”‚
â”‚  â”‚   â””â”€â”€ specialist_span (300ms)                           â”‚
â”‚                                                             â”‚
â”‚  MÃ‰TRICAS                                                  â”‚
â”‚  â€¢ Latencia promedio: 450ms                                â”‚
â”‚  â€¢ Tokens consumidos: 1,234                                â”‚
â”‚  â€¢ Tasa de Ã©xito: 98.5%                                    â”‚
â”‚                                                             â”‚
â”‚  LOGS                                                       â”‚
â”‚  â€¢ [INFO] Agente iniciado                                  â”‚
â”‚  â€¢ [DEBUG] Tool call: search_kb                            â”‚
â”‚  â€¢ [ERROR] Timeout en llamada LLM                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| SeÃ±al | PropÃ³sito |
|-------|-----------|
| **Traces** | Seguir flujo de ejecuciÃ³n |
| **MÃ©tricas** | Medir rendimiento |
| **Logs** | Depurar problemas |

### ğŸ§  PseudocÃ³digo

```
ALGORITMO: Agente con Observabilidad

1. CONFIGURAR OPENTELEMETRY:
   - TracerProvider con Azure exporter
   - Instrumentar framework de agentes

2. CREAR SPANS PERSONALIZADOS:
   - Envolver operaciones crÃ­ticas
   - AÃ±adir atributos relevantes

3. ENVIAR A AZURE MONITOR:
   - Connection string de App Insights
   - Traces y mÃ©tricas automÃ¡ticos
```

### ğŸ”¨ Ejercicio

Crea `src/module7_observability.py`.

<details>
<summary>ğŸ’¡ Hint: Configurar OpenTelemetry</summary>

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter

# Configurar proveedor de trazas
provider = TracerProvider()
exporter = AzureMonitorTraceExporter(
    connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
)
provider.add_span_processor(BatchSpanProcessor(exporter))
trace.set_tracer_provider(provider)

tracer = trace.get_tracer(__name__)
```

</details>

<details>
<summary>ğŸ’¡ Hint: Spans Personalizados</summary>

```python
with tracer.start_as_current_span("process_request") as span:
    span.set_attribute("user_id", user_id)
    span.set_attribute("request_type", "helpdesk")
    
    with tracer.start_as_current_span("agent_run") as agent_span:
        result = await agent.run(query)
        agent_span.set_attribute("tokens_used", result.usage.total_tokens)
```

</details>

### âœ… SoluciÃ³n

<details>
<summary>ğŸ“„ CÃ³digo Completo MÃ³dulo 7</summary>

```python
"""MÃ³dulo 7: Observabilidad con OpenTelemetry."""
import asyncio
import os
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.sdk.resources import Resource
from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter
from azure.identity import DefaultAzureCredential
from agent_framework.azure_openai import AzureOpenAIChatClient
from agent_framework import ai_function


def setup_telemetry() -> trace.Tracer:
    """Configura OpenTelemetry con Azure Monitor."""
    
    resource = Resource.create({
        "service.name": "helpdesk-agent",
        "service.version": "1.0.0",
        "deployment.environment": "development",
    })
    
    provider = TracerProvider(resource=resource)
    
    exporter = AzureMonitorTraceExporter(
        connection_string=os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
    )
    provider.add_span_processor(BatchSpanProcessor(exporter))
    
    trace.set_tracer_provider(provider)
    
    return trace.get_tracer(__name__)


@ai_function
def get_system_status(system_name: str) -> dict:
    """Obtiene el estado de un sistema."""
    return {"system": system_name, "status": "healthy", "uptime": "99.9%"}


async def main() -> None:
    """Demuestra observabilidad con trazas."""
    
    tracer = setup_telemetry()
    
    client = AzureOpenAIChatClient(
        credential=DefaultAzureCredential(),
        endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        deployment_name="gpt-4o",
    )
    
    agent = client.create_agent(
        name="ObservableAgent",
        instructions="Eres un asistente de TI con observabilidad.",
        tools=[get_system_status],
    )
    
    consultas = [
        "Â¿CuÃ¡l es el estado del servidor de correo?",
        "Verifica el sistema de autenticaciÃ³n",
    ]
    
    for consulta in consultas:
        # Crear span padre para toda la solicitud
        with tracer.start_as_current_span("helpdesk_request") as request_span:
            request_span.set_attribute("query", consulta)
            request_span.set_attribute("user_id", "user_123")
            
            print(f"\nğŸ‘¤ Usuario: {consulta}")
            
            # Span para ejecuciÃ³n del agente
            with tracer.start_as_current_span("agent_execution") as agent_span:
                result = await agent.run(consulta)
                
                agent_span.set_attribute("agent_name", "ObservableAgent")
                agent_span.set_attribute("response_length", len(result.text))
                
                if hasattr(result, 'usage'):
                    agent_span.set_attribute("tokens_prompt", result.usage.prompt_tokens)
                    agent_span.set_attribute("tokens_completion", result.usage.completion_tokens)
            
            print(f"ğŸ¤– Agente: {result.text}")
            request_span.set_attribute("status", "success")
    
    print("\nğŸ“Š Trazas enviadas a Azure Monitor")
    print("   Ver en: Portal Azure â†’ Application Insights â†’ BÃºsqueda de transacciones")


if __name__ == "__main__":
    asyncio.run(main())
```

</details>

```bash
pip install azure-monitor-opentelemetry-exporter
python src/module7_observability.py
```

---

## MÃ³dulo 8 â€” EvaluaciÃ³n y Pruebas

Implementa un pipeline de evaluaciÃ³n para medir la calidad de tu agente.

### ğŸ“š Concepto: Â¿Por quÃ© Evaluar?

| Sin EvaluaciÃ³n | Con EvaluaciÃ³n |
|----------------|----------------|
| "Parece que funciona bien" | "PrecisiÃ³n: 94.2%" |
| Cambios rompen funcionalidad | Regresiones detectadas |
| Calidad subjetiva | MÃ©tricas objetivas |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PIPELINE EVALUACIÃ“N                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. DATASET          2. EJECUCIÃ“N        3. MÃ‰TRICAS        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Preguntas   â”‚â”€â”€â”€â–¶â”‚   Agente    â”‚â”€â”€â”€â–¶â”‚ Comparar    â”‚     â”‚
â”‚  â”‚ Esperado    â”‚    â”‚   Responde  â”‚    â”‚ Evaluar     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                              â”‚              â”‚
â”‚                                              â–¼              â”‚
â”‚                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚                                        â”‚ â€¢ PrecisiÃ³n â”‚     â”‚
â”‚                                        â”‚ â€¢ Relevanciaâ”‚     â”‚
â”‚                                        â”‚ â€¢ Coherenciaâ”‚     â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ§  PseudocÃ³digo

```
ALGORITMO: EvaluaciÃ³n de Agente

1. CREAR DATASET DE PRUEBAS:
   - Lista de (pregunta, respuesta_esperada)
   - Cubrir casos normales y edge cases

2. EJECUTAR AGENTE EN DATASET:
   - Para cada pregunta, obtener respuesta
   - Guardar resultado

3. EVALUAR CON MÃ‰TRICAS:
   - Relevancia: Â¿responde a la pregunta?
   - Coherencia: Â¿es lÃ³gica la respuesta?
   - FundamentaciÃ³n: Â¿usa fuentes correctas?

4. GENERAR REPORTE:
   - Puntuaciones por mÃ©trica
   - Ejemplos de fallos
```

### ğŸ”¨ Ejercicio

Crea `src/module8_evaluation.py`.

<details>
<summary>ğŸ’¡ Hint: Dataset de Pruebas</summary>

```python
test_cases = [
    {
        "query": "Â¿CÃ³mo reinicio mi contraseÃ±a?",
        "expected_topics": ["contraseÃ±a", "portal", "autoservicio"],
        "expected_type": "procedural",
    },
    {
        "query": "Â¿CuÃ¡l es la polÃ­tica de contraseÃ±as?",
        "expected_topics": ["caracteres", "expiraciÃ³n", "complejidad"],
        "expected_type": "informational",
    },
]
```

</details>

<details>
<summary>ğŸ’¡ Hint: FunciÃ³n de EvaluaciÃ³n</summary>

```python
async def evaluate_response(
    query: str,
    response: str,
    expected_topics: list[str],
) -> dict:
    """EvalÃºa una respuesta del agente."""
    
    # Verificar cobertura de temas
    topics_found = sum(1 for t in expected_topics if t.lower() in response.lower())
    topic_coverage = topics_found / len(expected_topics)
    
    # Evaluar con LLM
    evaluator_prompt = f"""
    EvalÃºa esta respuesta del 1 al 5:
    Pregunta: {query}
    Respuesta: {response}
    
    Criterios:
    - Relevancia: Â¿responde a la pregunta?
    - Claridad: Â¿es fÃ¡cil de entender?
    - Completitud: Â¿cubre todos los aspectos?
    """
    
    return {
        "topic_coverage": topic_coverage,
        "relevance_score": ...,  # Del evaluador LLM
    }
```

</details>

### âœ… SoluciÃ³n

<details>
<summary>ğŸ“„ CÃ³digo Completo MÃ³dulo 8</summary>

```python
"""MÃ³dulo 8: EvaluaciÃ³n y Pruebas de Agentes."""
import asyncio
import os
from dataclasses import dataclass
from azure.identity import DefaultAzureCredential
from agent_framework.azure_openai import AzureOpenAIChatClient


@dataclass
class TestCase:
    """Caso de prueba para evaluaciÃ³n."""
    query: str
    expected_topics: list[str]
    category: str


@dataclass
class EvaluationResult:
    """Resultado de evaluaciÃ³n de un caso."""
    query: str
    response: str
    topic_coverage: float
    relevance_score: float
    passed: bool


# Dataset de pruebas
TEST_CASES = [
    TestCase(
        query="Â¿CÃ³mo reinicio mi contraseÃ±a de correo?",
        expected_topics=["contraseÃ±a", "portal", "restablecer", "pasos"],
        category="password",
    ),
    TestCase(
        query="No puedo conectar a la VPN",
        expected_topics=["VPN", "conexiÃ³n", "verificar", "credenciales"],
        category="network",
    ),
    TestCase(
        query="Â¿CuÃ¡l es el horario del soporte tÃ©cnico?",
        expected_topics=["horario", "soporte", "disponible"],
        category="general",
    ),
]


async def evaluate_single(
    agent,
    evaluator_agent,
    test_case: TestCase,
) -> EvaluationResult:
    """EvalÃºa un solo caso de prueba."""
    
    # Obtener respuesta del agente
    result = await agent.run(test_case.query)
    response = result.text
    
    # Calcular cobertura de temas
    topics_found = sum(
        1 for topic in test_case.expected_topics
        if topic.lower() in response.lower()
    )
    topic_coverage = topics_found / len(test_case.expected_topics)
    
    # Evaluar relevancia con LLM
    eval_prompt = f"""
    EvalÃºa la relevancia de esta respuesta (0.0 a 1.0):
    
    Pregunta: {test_case.query}
    Respuesta: {response}
    
    Responde SOLO con un nÃºmero entre 0.0 y 1.0.
    """
    
    eval_result = await evaluator_agent.run(eval_prompt)
    try:
        relevance_score = float(eval_result.text.strip())
    except ValueError:
        relevance_score = 0.5
    
    passed = topic_coverage >= 0.5 and relevance_score >= 0.6
    
    return EvaluationResult(
        query=test_case.query,
        response=response[:200] + "...",
        topic_coverage=topic_coverage,
        relevance_score=relevance_score,
        passed=passed,
    )


async def main() -> None:
    """Ejecuta pipeline de evaluaciÃ³n."""
    
    client = AzureOpenAIChatClient(
        credential=DefaultAzureCredential(),
        endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        deployment_name="gpt-4o",
    )
    
    # Agente a evaluar
    agent = client.create_agent(
        name="HelpdeskAgent",
        instructions="""Eres un asistente de TI.
        Proporciona respuestas Ãºtiles y detalladas.""",
    )
    
    # Agente evaluador
    evaluator = client.create_agent(
        name="Evaluator",
        instructions="EvalÃºa respuestas de IA. Responde solo con nÃºmeros.",
    )
    
    print("ğŸ§ª Iniciando evaluaciÃ³n...\n")
    print("=" * 60)
    
    results: list[EvaluationResult] = []
    
    for i, test_case in enumerate(TEST_CASES, 1):
        print(f"\nğŸ“‹ Caso {i}/{len(TEST_CASES)}: {test_case.category}")
        print(f"   Pregunta: {test_case.query[:50]}...")
        
        result = await evaluate_single(agent, evaluator, test_case)
        results.append(result)
        
        status = "âœ…" if result.passed else "âŒ"
        print(f"   {status} Cobertura: {result.topic_coverage:.0%}, Relevancia: {result.relevance_score:.0%}")
    
    # Resumen
    print("\n" + "=" * 60)
    print("ğŸ“Š RESUMEN DE EVALUACIÃ“N")
    print("=" * 60)
    
    passed = sum(1 for r in results if r.passed)
    total = len(results)
    avg_coverage = sum(r.topic_coverage for r in results) / total
    avg_relevance = sum(r.relevance_score for r in results) / total
    
    print(f"   Casos pasados: {passed}/{total} ({passed/total:.0%})")
    print(f"   Cobertura promedio: {avg_coverage:.0%}")
    print(f"   Relevancia promedio: {avg_relevance:.0%}")
    
    if passed == total:
        print("\nğŸ‰ Â¡Todos los casos pasaron!")
    else:
        print("\nâš ï¸ Algunos casos fallaron. Revisa las respuestas.")


if __name__ == "__main__":
    asyncio.run(main())
```

</details>

```bash
python src/module8_evaluation.py
```

<div class="task" data-title="ğŸ¯ DesafÃ­o">

> AÃ±ade mÃ©tricas adicionales: tiempo de respuesta, tokens usados, y genera un reporte JSON.

</div>

---

> ğŸŒ **[â† Parte 2: Conocimiento](./part2-knowledge.es.md)** | **[Parte 4: Avanzado y Recursos â†’](./part4-advanced.es.md)**
